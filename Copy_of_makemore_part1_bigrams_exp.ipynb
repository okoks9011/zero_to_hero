{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y38QQelKHoKY"
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fWMnOGePHoKa",
    "outputId": "b8c69851-1d03-42ec-a9ab-2971b872fdda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "stoi = {s:i+1 for i,s in enumerate(ascii_lowercase)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "stoi\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "opFEYYNlHoKb",
    "outputId": "b7dafc25-48c8-4ba7-fcc3-9f58200f51e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'e', 'm', 'm', 'a', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [list(f'.{w}.') for w in words]\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afHFQVqfHoKc"
   },
   "source": [
    "## E01\n",
    "train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EdBJIIu4HoKd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "BiLM = torch.zeros((27, 27), dtype=torch.int32)\n",
    "TriLM = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "\n",
    "for chs in tokens:\n",
    "    # bigram\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        BiLM[ix1, ix2] += 1\n",
    "        \n",
    "    # trigram\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        TriLM[ix1, ix2, ix3] += 1\n",
    "        \n",
    "BiP = (BiLM + 1).float()\n",
    "BiP /= BiP.sum(1, keepdims=True)\n",
    "\n",
    "TriP = (TriLM + 1).float()\n",
    "TriP /= TriP.sum(2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bkZFpYK9HoKd",
    "outputId": "83843d67-9327-4a92-8b11-d216279d1642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4543561935424805 vs 2.092747449874878 -> improved? YES\n"
     ]
    }
   ],
   "source": [
    "bi_log_likelihood = 0.0\n",
    "bi_n = 0\n",
    "\n",
    "tri_log_likelihood = 0.0\n",
    "tri_n = 0\n",
    "\n",
    "\n",
    "for chs in tokens:\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        prob = BiP[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        \n",
    "        bi_log_likelihood += logprob\n",
    "        bi_n += 1\n",
    "        \n",
    "    # trigram\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        prob = TriP[ix1, ix2, ix3]\n",
    "        logprob = torch.log(prob)\n",
    "        \n",
    "        tri_log_likelihood += logprob\n",
    "        tri_n += 1\n",
    "\n",
    "bi_loss = -bi_log_likelihood / bi_n\n",
    "tri_loss = -tri_log_likelihood / tri_n\n",
    "\n",
    "print(f'{bi_loss} vs {tri_loss} -> improved? {\"YES\" if tri_loss < bi_loss else \"NO\"}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU_iYLwGHoKe"
   },
   "source": [
    "## E02\n",
    "split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "htTa2jdWHoKe",
    "outputId": "31e2179b-c105-48d0-a4b4-77ab5ada8435"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_data, dev_data, test_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrandom_split(tokens, [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m], generator\u001b[38;5;241m=\u001b[39m\u001b[43mg\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# train models\u001b[39;00m\n\u001b[1;32m      7\u001b[0m BiLM \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m27\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "train_data, dev_data, test_data = torch.utils.data.random_split(tokens, [0.8, 0.1, 0.1], generator=g)\n",
    "\n",
    "# train models\n",
    "BiLM = torch.zeros((27, 27), dtype=torch.int32)\n",
    "TriLM = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "\n",
    "for chs in train_data:\n",
    "    # bigram\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        BiLM[ix1, ix2] += 1\n",
    "        \n",
    "    # trigram\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "        TriLM[ix1, ix2] += 1\n",
    "\n",
    "BiP = (BiLM + 1).float()\n",
    "BiP /= BiP.sum(1, keepdims=True)\n",
    "\n",
    "TriP = (TriLM+1).float()\n",
    "TriP /= TriP.sum(2, keepdims=True)\n",
    "\n",
    "# evaluate models\n",
    "def eval_nll(data):\n",
    "    bi_lll = tri_lll = 0.0\n",
    "    bi_n = tri_n = 0\n",
    "    \n",
    "    for chs in data:\n",
    "        for ch1, ch2 in zip(chs, chs[1:]):\n",
    "            ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "            \n",
    "            logprob = torch.log(BiP[ix1, ix2])\n",
    "            bi_lll += logprob\n",
    "            bi_n += 1\n",
    "\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "            \n",
    "            logprob = torch.log(TriP[ix1, ix2, ix3])\n",
    "            tri_lll += logprob\n",
    "            tri_n += 1\n",
    "            \n",
    "    return (-bi_lll/bi_n).item(), (-tri_lll/tri_n).item()\n",
    "\n",
    "\n",
    "dev_bi_nll, dev_tri_nll = eval_nll(dev_data)\n",
    "print(f'on dev set: {dev_bi_nll} vs {dev_tri_nll}')\n",
    "      \n",
    "\n",
    "test_bi_nll, test_tri_nll = eval_nll(test_data)\n",
    "print(f'on test set: {test_bi_nll} vs {test_tri_nll}')\n",
    "\n",
    "# bi becomes worse, tri becomes better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCFTLWnyHoKf"
   },
   "source": [
    "## E03\n",
    "use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ez4BAUCeHoKf"
   },
   "outputs": [],
   "source": [
    "P = (TriLM+0.5).float()\n",
    "P /= P.sum(2, keepdims=True)\n",
    "\n",
    "# evaluate models\n",
    "def eval_nll(data):\n",
    "    lll = 0.0\n",
    "    n = 0\n",
    "    \n",
    "    for chs in data:\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            ix1, ix2, ix3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
    "            \n",
    "            logprob = torch.log(P[ix1, ix2, ix3])\n",
    "            lll += logprob\n",
    "            n += 1\n",
    "            \n",
    "    return (-lll/n).item()\n",
    "\n",
    "\n",
    "dev_nll = eval_nll(dev_data)\n",
    "print(f'on dev set: {dev_nll}')\n",
    "      \n",
    "\n",
    "test_nll = eval_nll(test_data)\n",
    "print(f'on test set: {test_nll}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip7MEgEKHoKg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTXMzq05HoKg"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. \n",
    " Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "# for w in words[:10]:\n",
    "new_words = words.copy()\n",
    "random.shuffle(new_words)\n",
    "capacity = len(new_words)\n",
    "\n",
    "base_idx = capacity // 10\n",
    "train_set = new_words[:base_idx * 8]\n",
    "dev_set = new_words[base_idx * 8:base_idx * 9]\n",
    "test_set = new_words[base_idx * 9:]\n",
    "\n",
    "print(f'train_set: {len(train_set)}, dev_set: {len(dev_set)}, test_set: {len(test_set)}')\n",
    "\n",
    "\n",
    "# train language model\n",
    "bigram_lm = BigramLM()\n",
    "trigram_lm = TrigramLM()\n",
    "for train_data in train_set:\n",
    "    bigram_lm.update_counts(train_data)\n",
    "    trigram_lm.update_counts(train_data)\n",
    "bigram_lm.calculate_probabilities()\n",
    "trigram_lm.calculate_probabilities()\n",
    "\n",
    "# evaluate dev set\n",
    "for dev_data in dev_set:\n",
    "    bigram_dev_loss = bigram_lm.calculate_loss(dev_data)\n",
    "    trigram_dev_loss = trigram_lm.calculate_loss(dev_data)\n",
    "    print(f\"Bigram/Trigram dev loss: {bigram_dev_loss:.4f} vs {trigram_dev_loss:.4f}\")\n",
    "\n",
    "# evaluate test set\n",
    "for test_data in test_set:\n",
    "    bigram_test_loss = bigram_lm.calculate_loss(test_data)\n",
    "    trigram_test_loss = trigram_lm.calculate_loss(test_data)\n",
    "    print(f\"Bigram/Trigram test loss: {bigram_test_loss:.4f} vs {trigram_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwG-folYHoKg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KN2dmWCHoKg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t4Xb2oIHoKg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
